{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zqSzt__Iul8",
        "outputId": "890ffb3e-f7c9-4ac0-b17a-3f355ddb61a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "S&P 500 MULTI-FACTOR STOCK SCREENING ALGORITHM\n",
            "================================================================================\n",
            "Fetching S&P 500 tickers...\n",
            "✓ Successfully loaded 501 S&P 500 tickers from Wikipedia\n",
            "\n",
            "Downloading stock data for 501 tickers...\n",
            "Using batch processing to avoid rate limits...\n",
            "\n",
            "Processing batch 1: Tickers 1-50\n",
            "Overall progress: 25/501 tickers (24 successful)\n",
            "Overall progress: 50/501 tickers (49 successful)\n",
            "Pausing 1 seconds before next batch...\n",
            "\n",
            "Processing batch 2: Tickers 51-100\n",
            "Overall progress: 75/501 tickers (74 successful)\n",
            "Overall progress: 100/501 tickers (99 successful)\n",
            "Pausing 1 seconds before next batch...\n",
            "\n",
            "Processing batch 3: Tickers 101-150\n",
            "Overall progress: 125/501 tickers (124 successful)\n",
            "Overall progress: 150/501 tickers (149 successful)\n",
            "Pausing 1 seconds before next batch...\n",
            "\n",
            "Processing batch 4: Tickers 151-200\n",
            "Overall progress: 175/501 tickers (174 successful)\n",
            "Overall progress: 200/501 tickers (199 successful)\n",
            "Pausing 1 seconds before next batch...\n",
            "\n",
            "Processing batch 5: Tickers 201-250\n",
            "Overall progress: 225/501 tickers (224 successful)\n",
            "Overall progress: 250/501 tickers (249 successful)\n",
            "Pausing 1 seconds before next batch...\n",
            "\n",
            "Processing batch 6: Tickers 251-300\n",
            "Overall progress: 275/501 tickers (274 successful)\n",
            "Overall progress: 300/501 tickers (299 successful)\n",
            "Pausing 1 seconds before next batch...\n",
            "\n",
            "Processing batch 7: Tickers 301-350\n",
            "Overall progress: 325/501 tickers (324 successful)\n",
            "Overall progress: 350/501 tickers (349 successful)\n",
            "Pausing 1 seconds before next batch...\n",
            "\n",
            "Processing batch 8: Tickers 351-400\n",
            "Overall progress: 375/501 tickers (374 successful)\n",
            "Overall progress: 400/501 tickers (398 successful)\n",
            "Pausing 1 seconds before next batch...\n",
            "\n",
            "Processing batch 9: Tickers 401-450\n",
            "Overall progress: 425/501 tickers (421 successful)\n",
            "Overall progress: 450/501 tickers (446 successful)\n",
            "Pausing 1 seconds before next batch...\n",
            "\n",
            "Processing batch 10: Tickers 451-500\n",
            "Overall progress: 475/501 tickers (471 successful)\n",
            "Overall progress: 500/501 tickers (496 successful)\n",
            "Pausing 1 seconds before next batch...\n",
            "\n",
            "Processing batch 11: Tickers 501-501\n",
            "\n",
            "============================================================\n",
            "DOWNLOAD COMPLETE\n",
            "============================================================\n",
            "✓ Successfully downloaded: 498 stocks\n",
            "✗ Failed downloads: 3 stocks\n",
            "Failed tickers: Q, SNDK, SOLS\n",
            "\n",
            "Calculating factor scores for all stocks...\n",
            "Scoring progress: 50/498 stocks\n",
            "Scoring progress: 100/498 stocks\n",
            "Scoring progress: 150/498 stocks\n",
            "Scoring progress: 200/498 stocks\n",
            "Scoring progress: 250/498 stocks\n",
            "Scoring progress: 300/498 stocks\n",
            "Scoring progress: 350/498 stocks\n",
            "Scoring progress: 400/498 stocks\n",
            "Scoring progress: 450/498 stocks\n",
            "Total stocks before filtering: 498\n",
            "Stocks after filtering (3+ valid scores): 498\n",
            "\n",
            "Normalizing factor scores...\n",
            "After liquidity filter (removed bottom 20%): 498 stocks\n",
            "final rankings: 498 stocks\n",
            "\n",
            "✓ Results exported to sp500_stock_picks.csv\n",
            "\n",
            "================================================================================\n",
            "SCREENING COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "Total stocks ranked: 498\n",
            "Top picks selected: 50\n",
            "Results saved\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "import requests\n",
        "import time\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class SNP500StockScreener:\n",
        "    def __init__(self):\n",
        "        self.sp500_tickers = []\n",
        "        self.stock_data = {}\n",
        "        self.factor_scores = pd.DataFrame()\n",
        "        self.final_rankings = pd.DataFrame()\n",
        "\n",
        "    def get_sp500_tickers(self):\n",
        "        \"\"\"\n",
        "        Fetch S&P 500 tickers with multiple fallback methods\n",
        "        \"\"\"\n",
        "        print(\"Fetching S&P 500 tickers\")\n",
        "\n",
        "        # Method 1: Wikipedia Scraping\n",
        "        try:\n",
        "            headers = {\n",
        "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "            }\n",
        "            url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
        "\n",
        "            response = requests.get(url, headers=headers, timeout=10)\n",
        "            tables = pd.read_html(response.text)\n",
        "            sp500_table = tables[0]\n",
        "\n",
        "            tickers = sp500_table['Symbol'].tolist()\n",
        "            tickers = [ticker.replace('.', '-') for ticker in tickers]\n",
        "\n",
        "            self.sp500_tickers = tickers\n",
        "            print(f\"Successfully loaded {len(tickers)} from Wikipedia\")\n",
        "            return tickers\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Wikipedia method failed: {e}\")\n",
        "\n",
        "        # Method 2: yfinance\n",
        "        try:\n",
        "            print(\"Trying alternative method: Fetching from SPY ETF...\")\n",
        "            spy = yf.Ticker(\"SPY\")\n",
        "            holdings = spy.get_holdings()\n",
        "\n",
        "            if holdings is not None and len(holdings) > 0:\n",
        "                tickers = holdings.index.tolist()[:500]  # Top 500\n",
        "                self.sp500_tickers = tickers\n",
        "                print(f\"Successfully loaded {len(tickers)} from yfinance\")\n",
        "                return tickers\n",
        "        except Exception as e:\n",
        "            print(f\"yfinance method failed: {e}\")\n",
        "\n",
        "        # Method 3: manual list\n",
        "        print(\"using fallback manual list\")\n",
        "        self.sp500_tickers = self._get_manual_sp500_list()\n",
        "        print(f\"Loaded {len(self.sp500_tickers)} tickers from manual list\")\n",
        "        return self.sp500_tickers\n",
        "\n",
        "    def _get_manual_sp500_list(self): #using manual list\n",
        "        sp500_tickers = [\n",
        "            # Mega Cap Tech\n",
        "            'AAPL', 'MSFT', 'GOOGL', 'GOOG', 'AMZN', 'NVDA', 'META', 'TSLA',\n",
        "            'BRK-B', 'AVGO', 'LLY', 'JPM', 'V', 'UNH', 'XOM', 'MA', 'COST',\n",
        "            'HD', 'PG', 'JNJ', 'NFLX', 'ABBV', 'BAC', 'CRM', 'ORCL', 'CVX',\n",
        "            'KO', 'AMD', 'MRK', 'PEP', 'ADBE', 'TMO', 'WMT', 'CSCO', 'ACN',\n",
        "            'MCD', 'ABT', 'NKE', 'LIN', 'DHR', 'QCOM', 'TXN', 'PM', 'INTC',\n",
        "            'VZ', 'DIS', 'INTU', 'CMCSA', 'AMGN', 'IBM', 'UNP', 'NEE', 'RTX',\n",
        "            'HON', 'COP', 'SPGI', 'GE', 'LOW', 'CAT', 'UBER', 'AXP', 'BA',\n",
        "            'T', 'PLD', 'DE', 'BLK', 'GS', 'NOW', 'MS', 'ELV', 'AMAT', 'BKNG',\n",
        "            'SYK', 'PFE', 'VRTX', 'TJX', 'ADP', 'SBUX', 'GILD', 'MMC', 'ADI',\n",
        "            'MDLZ', 'LRCX', 'C', 'AMT', 'REGN', 'CVS', 'CI', 'ISRG', 'SCHW',\n",
        "\n",
        "            # Large Cap\n",
        "            'ZTS', 'PGR', 'MO', 'CB', 'SO', 'BDX', 'DUK', 'BMY', 'PANW', 'NOC',\n",
        "            'ETN', 'APH', 'BSX', 'CME', 'TT', 'ITW', 'KLAC', 'MCO', 'SNPS',\n",
        "            'WM', 'EOG', 'ICE', 'HCA', 'USB', 'CL', 'MSI', 'FI', 'SHW', 'EMR',\n",
        "            'CSX', 'GD', 'MCK', 'NSC', 'APD', 'PSA', 'MAR', 'PH', 'AON', 'ECL',\n",
        "            'PYPL', 'MMM', 'ORLY', 'TDG', 'BK', 'AJG', 'TGT', 'PCAR', 'GM',\n",
        "            'JCI', 'ROP', 'AFL', 'MET', 'SLB', 'HUM', 'ADSK', 'SRE', 'CARR',\n",
        "            'NXPI', 'TRV', 'AIG', 'ALL', 'MNST', 'AEP', 'CMG', 'AZO', 'ROST',\n",
        "            'MCHP', 'KMB', 'O', 'D', 'EW', 'PAYX', 'PRU', 'KMI', 'SPG', 'EXC',\n",
        "            'MSCI', 'WELL', 'CCI', 'TEL', 'FAST', 'HES', 'CPRT', 'GWW', 'ODFL',\n",
        "            'CTVA', 'F', 'CTAS', 'A', 'KDP', 'LHX', 'EA', 'DXCM', 'YUM', 'DLR',\n",
        "\n",
        "            # Mid Cap\n",
        "            'PCG', 'IQV', 'DHI', 'VRSK', 'XEL', 'RSG', 'AME', 'FANG', 'ED',\n",
        "            'DD', 'ACGL', 'CHTR', 'WMB', 'MTD', 'KHC', 'IDXX', 'DAL', 'EXR',\n",
        "            'VICI', 'ROK', 'ANSS', 'RMD', 'GLW', 'IR', 'OTIS', 'WEC', 'ON',\n",
        "            'CDNS', 'CSGP', 'EBAY', 'GEHC', 'DOW', 'KEYS', 'CDW', 'IT', 'GPN',\n",
        "            'EIX', 'FICO', 'STZ', 'VMC', 'AWK', 'MLM', 'PPG', 'MPWR', 'NUE',\n",
        "            'CHD', 'RJF', 'FITB', 'WBD', 'WY', 'BKR', 'DFS', 'NDAQ', 'HPQ',\n",
        "            'IFF', 'ETR', 'SBAC', 'ZBH', 'APTV', 'NTRS', 'WDC', 'PTC', 'CAH',\n",
        "            'MTB', 'FDS', 'LYB', 'TSCO', 'LUV', 'TTWO', 'INVH', 'TROW', 'LH',\n",
        "            'FTV', 'STT', 'BAX', 'BR', 'HAL', 'HPE', 'ARE', 'STLD', 'ALGN',\n",
        "            'EPAM', 'SYF', 'TYL', 'CBRE', 'K', 'EFX', 'RF', 'NTAP', 'MKC',\n",
        "\n",
        "            # Additional\n",
        "            'ESS', 'DTE', 'MAA', 'IRM', 'EQR', 'PKG', 'BALL', 'HBAN', 'SWK',\n",
        "            'EXPE', 'AEE', 'DOV', 'VTR', 'EQT', 'IP', 'PPL', 'HOLX', 'CFG',\n",
        "            'WAB', 'OMC', 'AVB', 'CNP', 'DGX', 'CINF', 'LEN', 'CLX', 'TDY',\n",
        "            'FE', 'VLTO', 'CBOE', 'ATO', 'MAS', 'ZBRA', 'WAT', 'TER', 'JBHT',\n",
        "            'PFG', 'NVR', 'J', 'DRI', 'UAL', 'COF', 'CAG', 'LDOS', 'LVS',\n",
        "            'TRMB', 'DPZ', 'BLDR', 'STE', 'HIG', 'HSY', 'XYL', 'TSN', 'BBY',\n",
        "            'GPC', 'POOL', 'CE', 'LKQ', 'TXT', 'AKAM', 'CMS', 'PKI', 'SNA',\n",
        "            'CPT', 'MOS', 'JKHY', 'LNT', 'EVRG', 'SWKS', 'GL', 'NDSN', 'FFIV',\n",
        "            'HSIC', 'NI', 'GNRC', 'UDR', 'TAP', 'CPB', 'CHRW', 'BXP', 'MTCH',\n",
        "            'BG', 'AIZ', 'HWM', 'AAL', 'PARA', 'FOXA', 'FOX', 'ALB', 'HII',\n",
        "            'TPR', 'RL', 'AOS', 'WYNN', 'IVZ', 'NWSA', 'NWS', 'ZION', 'RHI',\n",
        "            'PNW', 'WHR', 'BWA', 'NCLH', 'HAS', 'REG', 'KIM', 'FRT', 'VNO',\n",
        "        ]\n",
        "\n",
        "        return sp500_tickers\n",
        "\n",
        "    def download_stock_data(self, lookback_months=36, batch_size=50, delay=1):\n",
        "        \"\"\"\n",
        "        Download historical data with rate limiting and batch processing\n",
        "\n",
        "        batch_size: Number of stocks to download before pausing\n",
        "        delay: Seconds to wait between batches\n",
        "        \"\"\"\n",
        "        print(f\"\\nDownloading stock data for {len(self.sp500_tickers)} tickers...\")\n",
        "        print(\"Using batch processing to avoid rate limits...\")\n",
        "\n",
        "        end_date = datetime.now()\n",
        "        start_date = end_date - timedelta(days=lookback_months*30)\n",
        "\n",
        "        successful_downloads = 0\n",
        "        failed_tickers = []\n",
        "\n",
        "        # Process in batches\n",
        "        total_tickers = len(self.sp500_tickers)\n",
        "\n",
        "        for batch_start in range(0, total_tickers, batch_size):\n",
        "            batch_end = min(batch_start + batch_size, total_tickers)\n",
        "            batch_tickers = self.sp500_tickers[batch_start:batch_end]\n",
        "\n",
        "            print(f\"\\nProcessing batch {batch_start//batch_size + 1}: Tickers {batch_start+1}-{batch_end}\")\n",
        "\n",
        "            for i, ticker in enumerate(batch_tickers):\n",
        "                try:\n",
        "                    # Progress indicator\n",
        "                    overall_progress = batch_start + i + 1\n",
        "                    if overall_progress % 25 == 0:\n",
        "                        print(f\"Overall progress: {overall_progress}/{total_tickers} tickers ({successful_downloads} successful)\")\n",
        "\n",
        "                    # Download with timeout\n",
        "                    stock = yf.Ticker(ticker)\n",
        "\n",
        "                    # Download price history\n",
        "                    hist = stock.history(start=start_date, end=end_date, timeout=10)\n",
        "\n",
        "                    if len(hist) < 252:  # Need at least 1 year of data\n",
        "                        failed_tickers.append(ticker)\n",
        "                        continue\n",
        "\n",
        "                    # Get fundamental data\n",
        "                    info = stock.info\n",
        "\n",
        "                    # Validate we have minimum required data\n",
        "                    if not info or 'marketCap' not in info:\n",
        "                        failed_tickers.append(ticker)\n",
        "                        continue\n",
        "\n",
        "                    # Store data\n",
        "                    self.stock_data[ticker] = {\n",
        "                        'history': hist,\n",
        "                        'info': info\n",
        "                    }\n",
        "\n",
        "                    successful_downloads += 1\n",
        "\n",
        "                    # delay to avoid overwhelming the API\n",
        "                    time.sleep(0.1)\n",
        "\n",
        "                except Exception as e:\n",
        "                    failed_tickers.append(ticker)\n",
        "                    continue\n",
        "\n",
        "            # Pause between batches to avoid rate limiting\n",
        "            if batch_end < total_tickers:\n",
        "                print(f\"Pausing {delay} seconds before next batch...\")\n",
        "                time.sleep(delay)\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"DOWNLOAD COMPLETE\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Successfully downloaded: {successful_downloads} stocks\")\n",
        "        print(f\"Failed downloads: {len(failed_tickers)} stocks\")\n",
        "\n",
        "        if len(failed_tickers) > 0 and len(failed_tickers) < 20:\n",
        "            print(f\"Failed tickers: {', '.join(failed_tickers)}\")\n",
        "\n",
        "        return successful_downloads\n",
        "\n",
        "    def download_stock_data_parallel(self, lookback_months=36, max_workers=5):\n",
        "        from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "        print(f\"\\nDownloading stock data using {max_workers} parallel workers...\")\n",
        "\n",
        "        end_date = datetime.now()\n",
        "        start_date = end_date - timedelta(days=lookback_months*30)\n",
        "\n",
        "        successful_downloads = 0\n",
        "        failed_tickers = []\n",
        "\n",
        "        def download_single_stock(ticker):\n",
        "            \"\"\"Helper function to download single stock\"\"\"\n",
        "            try:\n",
        "                stock = yf.Ticker(ticker)\n",
        "                hist = stock.history(start=start_date, end=end_date, timeout=10)\n",
        "\n",
        "                if len(hist) < 252:\n",
        "                    return ticker, None, \"Insufficient data\"\n",
        "\n",
        "                info = stock.info\n",
        "\n",
        "                if not info or 'marketCap' not in info:\n",
        "                    return ticker, None, \"No fundamental data\"\n",
        "\n",
        "                return ticker, {'history': hist, 'info': info}, None\n",
        "\n",
        "            except Exception as e:\n",
        "                return ticker, None, str(e)\n",
        "\n",
        "        # Download in parallel\n",
        "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "            future_to_ticker = {\n",
        "                executor.submit(download_single_stock, ticker): ticker\n",
        "                for ticker in self.sp500_tickers\n",
        "            }\n",
        "\n",
        "            for i, future in enumerate(as_completed(future_to_ticker)):\n",
        "                ticker, data, error = future.result()\n",
        "\n",
        "                if data is not None:\n",
        "                    self.stock_data[ticker] = data\n",
        "                    successful_downloads += 1\n",
        "                else:\n",
        "                    failed_tickers.append(ticker)\n",
        "\n",
        "                # Progress update\n",
        "                if (i + 1) % 50 == 0:\n",
        "                    print(f\"Progress: {i+1}/{len(self.sp500_tickers)} ({successful_downloads} successful)\")\n",
        "\n",
        "        print(f\"\\nSuccessfully downloaded: {successful_downloads} stocks\")\n",
        "        print(f\"Failed downloads: {len(failed_tickers)} stocks\")\n",
        "\n",
        "        return successful_downloads\n",
        "\n",
        "\n",
        "    def calculate_momentum_score(self, ticker):\n",
        "        \"\"\"Calculate 12-month momentum excluding most recent month\"\"\"\n",
        "        try:\n",
        "            hist = self.stock_data[ticker]['history']\n",
        "\n",
        "            if len(hist) < 252:\n",
        "                return np.nan\n",
        "\n",
        "            price_12m_ago = hist['Close'].iloc[-252]\n",
        "            price_1m_ago = hist['Close'].iloc[-21]\n",
        "\n",
        "            momentum_return = (price_1m_ago - price_12m_ago) / price_12m_ago\n",
        "\n",
        "            returns = hist['Close'].pct_change().dropna()\n",
        "            volatility = returns.std() * np.sqrt(252)\n",
        "\n",
        "            if volatility > 0:\n",
        "                risk_adjusted_momentum = momentum_return / volatility\n",
        "            else:\n",
        "                risk_adjusted_momentum = 0\n",
        "\n",
        "            return risk_adjusted_momentum\n",
        "\n",
        "        except Exception as e:\n",
        "            return np.nan\n",
        "\n",
        "    def calculate_quality_score(self, ticker):\n",
        "        \"\"\"Calculate quality score\"\"\"\n",
        "        try:\n",
        "            info = self.stock_data[ticker]['info']\n",
        "\n",
        "            roe = info.get('returnOnEquity', 0) * 100 if info.get('returnOnEquity') else 0\n",
        "\n",
        "            market_cap = info.get('marketCap', 1)\n",
        "            free_cash_flow = info.get('freeCashflow', 0)\n",
        "            fcf_yield = (free_cash_flow / market_cap * 100) if market_cap > 0 else 0\n",
        "\n",
        "            debt_to_equity = info.get('debtToEquity', 100) / 100 if info.get('debtToEquity') else 1\n",
        "\n",
        "            operating_margin = info.get('operatingMargins', 0) * 100 if info.get('operatingMargins') else 0\n",
        "\n",
        "            roe_score = min(roe / 15 * 25, 25)\n",
        "            fcf_score = min(fcf_yield / 5 * 25, 25)\n",
        "            debt_score = max(25 - debt_to_equity * 10, 0)\n",
        "            margin_score = min(operating_margin / 20 * 25, 25)\n",
        "\n",
        "            quality_score = roe_score + fcf_score + debt_score + margin_score\n",
        "\n",
        "            return quality_score\n",
        "\n",
        "        except Exception as e:\n",
        "            return np.nan\n",
        "\n",
        "    def calculate_value_score(self, ticker):\n",
        "        \"\"\"Calculate value score\"\"\"\n",
        "        try:\n",
        "            info = self.stock_data[ticker]['info']\n",
        "\n",
        "            market_cap = info.get('marketCap', 1)\n",
        "            free_cash_flow = info.get('freeCashflow', 0)\n",
        "            fcf_yield = (free_cash_flow / market_cap * 100) if market_cap > 0 else 0\n",
        "\n",
        "            price_to_book = info.get('priceToBook', 10)\n",
        "            book_yield = (1 / price_to_book * 100) if price_to_book > 0 else 0\n",
        "\n",
        "            pe_ratio = info.get('trailingPE', 30)\n",
        "            earnings_yield = (1 / pe_ratio * 100) if pe_ratio > 0 else 0\n",
        "\n",
        "            fcf_score = min(fcf_yield / 8 * 40, 40)\n",
        "            book_score = min(book_yield / 15 * 30, 30)\n",
        "            earnings_score = min(earnings_yield / 5 * 30, 30)\n",
        "\n",
        "            value_score = fcf_score + book_score + earnings_score\n",
        "\n",
        "            return value_score\n",
        "\n",
        "        except Exception as e:\n",
        "            return np.nan\n",
        "\n",
        "    def calculate_low_volatility_score(self, ticker):\n",
        "        \"\"\"Calculate low volatility score\"\"\"\n",
        "        try:\n",
        "            hist = self.stock_data[ticker]['history']\n",
        "\n",
        "            returns = hist['Close'].pct_change().dropna()\n",
        "            volatility = returns.std() * np.sqrt(252)\n",
        "\n",
        "            beta = self.stock_data[ticker]['info'].get('beta', 1.0)\n",
        "\n",
        "            vol_score = max(100 - (volatility * 200), 0)\n",
        "            beta_score = max(100 - (beta * 50), 0)\n",
        "\n",
        "            low_vol_score = (vol_score * 0.7 + beta_score * 0.3)\n",
        "\n",
        "            return low_vol_score\n",
        "\n",
        "        except Exception as e:\n",
        "            return np.nan\n",
        "\n",
        "    def calculate_liquidity_score(self, ticker):\n",
        "        \"\"\"Calculate liquidity score\"\"\"\n",
        "        try:\n",
        "            hist = self.stock_data[ticker]['history']\n",
        "\n",
        "            avg_volume = hist['Volume'].iloc[-60:].mean()\n",
        "            current_price = hist['Close'].iloc[-1]\n",
        "            dollar_volume = avg_volume * current_price\n",
        "\n",
        "            liquidity_score = min(dollar_volume / 10_000_000 * 100, 100)\n",
        "\n",
        "            return liquidity_score\n",
        "\n",
        "        except Exception as e:\n",
        "            return np.nan\n",
        "\n",
        "    def screen_stocks(self, factor_weights=None):\n",
        "      \"\"\"Main screening function with more flexible criteria\"\"\"\n",
        "      if factor_weights is None:\n",
        "          factor_weights = {\n",
        "              'momentum': 0.40,\n",
        "              'quality': 0.30,\n",
        "              'value': 0.20,\n",
        "              'low_vol': 0.10\n",
        "          }\n",
        "\n",
        "      print(\"\\nCalculating factor scores for all stocks...\")\n",
        "\n",
        "      results = []\n",
        "\n",
        "      for i, ticker in enumerate(self.stock_data.keys()):\n",
        "          if (i + 1) % 50 == 0:\n",
        "              print(f\"Scoring progress: {i+1}/{len(self.stock_data)} stocks\")\n",
        "\n",
        "          try:\n",
        "              momentum = self.calculate_momentum_score(ticker)\n",
        "              quality = self.calculate_quality_score(ticker)\n",
        "              value = self.calculate_value_score(ticker)\n",
        "              low_vol = self.calculate_low_volatility_score(ticker)\n",
        "              liquidity = self.calculate_liquidity_score(ticker)\n",
        "\n",
        "              info = self.stock_data[ticker]['info']\n",
        "              current_price = self.stock_data[ticker]['history']['Close'].iloc[-1]\n",
        "              company_name = info.get('longName', ticker)\n",
        "              sector = info.get('sector', 'Unknown')\n",
        "\n",
        "              results.append({\n",
        "                  'Ticker': ticker,\n",
        "                  'Company': company_name,\n",
        "                  'Sector': sector,\n",
        "                  'Price': round(current_price, 2),\n",
        "                  'Momentum_Score': momentum,\n",
        "                  'Quality_Score': quality,\n",
        "                  'Value_Score': value,\n",
        "                  'LowVol_Score': low_vol,\n",
        "                  'Liquidity_Score': liquidity\n",
        "              })\n",
        "\n",
        "          except Exception as e:\n",
        "              continue\n",
        "\n",
        "      self.factor_scores = pd.DataFrame(results)\n",
        "\n",
        "      print(f\"Total stocks before filtering: {len(self.factor_scores)}\")\n",
        "\n",
        "      # Count how many valid scores each stock has\n",
        "      score_columns = ['Momentum_Score', 'Quality_Score', 'Value_Score', 'LowVol_Score']\n",
        "      self.factor_scores['Valid_Scores'] = self.factor_scores[score_columns].notna().sum(axis=1)\n",
        "\n",
        "      # Keep stocks with at least 3 out of 4 valid scores\n",
        "      self.factor_scores = self.factor_scores[self.factor_scores['Valid_Scores'] >= 3]\n",
        "\n",
        "      print(f\"Stocks after filtering (3+ valid scores): {len(self.factor_scores)}\")\n",
        "\n",
        "      # Fill missing scores with median\n",
        "      for factor in score_columns:\n",
        "          median_score = self.factor_scores[factor].median()\n",
        "          self.factor_scores[factor].fillna(median_score, inplace=True)\n",
        "\n",
        "      print(\"\\nNormalizing factor scores...\")\n",
        "\n",
        "      # Normalize to z-scores\n",
        "      for factor in score_columns:\n",
        "          mean = self.factor_scores[factor].mean()\n",
        "          std = self.factor_scores[factor].std()\n",
        "          if std > 0:\n",
        "              self.factor_scores[f'{factor}_Z'] = (self.factor_scores[factor] - mean) / std\n",
        "          else:\n",
        "              self.factor_scores[f'{factor}_Z'] = 0\n",
        "\n",
        "      # Calculate composite score\n",
        "      self.factor_scores['Composite_Score'] = (\n",
        "          self.factor_scores['Momentum_Score_Z'] * factor_weights['momentum'] +\n",
        "          self.factor_scores['Quality_Score_Z'] * factor_weights['quality'] +\n",
        "          self.factor_scores['Value_Score_Z'] * factor_weights['value'] +\n",
        "          self.factor_scores['LowVol_Score_Z'] * factor_weights['low_vol']\n",
        "      )\n",
        "\n",
        "      # filter\n",
        "      if len(self.factor_scores) > 10:\n",
        "          liquidity_threshold = self.factor_scores['Liquidity_Score'].quantile(0.20)\n",
        "          before_liq_filter = len(self.factor_scores)\n",
        "          self.factor_scores = self.factor_scores[\n",
        "              self.factor_scores['Liquidity_Score'] >= liquidity_threshold\n",
        "          ]\n",
        "          print(f\"After liquidity filter (removed bottom 20%): {len(self.factor_scores)} stocks\")\n",
        "\n",
        "      # rank final\n",
        "      self.factor_scores['Rank'] = self.factor_scores['Composite_Score'].rank(ascending=False)\n",
        "\n",
        "      # sort by comp score\n",
        "      self.final_rankings = self.factor_scores.sort_values('Composite_Score', ascending=False)\n",
        "\n",
        "      print(f\"final rankings: {len(self.final_rankings)} stocks\")\n",
        "\n",
        "      return self.final_rankings\n",
        "\n",
        "    def get_top_stocks(self, n=50, min_composite_percentile=None):\n",
        "        \"\"\"\n",
        "        Get top N stocksE\n",
        "\n",
        "        n: Number of stocks to return\n",
        "        min_composite_percentile: Optional filter (e.g., 0.5 for top 50%)\n",
        "        \"\"\"\n",
        "        df = self.final_rankings.copy()\n",
        "\n",
        "        # Optional to Filter by composite score percentile only\n",
        "        if min_composite_percentile:\n",
        "            threshold = df['Composite_Score'].quantile(1 - min_composite_percentile)\n",
        "            df = df[df['Composite_Score'] >= threshold]\n",
        "            print(f\"After percentile filter: {len(df)} stocks remain\")\n",
        "\n",
        "        # return top N by composite score\n",
        "        top_stocks = df.head(n)\n",
        "\n",
        "        return top_stocks\n",
        "\n",
        "    def get_stock_pick_summary(self, top_n=50):\n",
        "        \"\"\"\n",
        "        Generate summary report\n",
        "        \"\"\"\n",
        "        # REMOVED the strict min_per_factor requirement\n",
        "        top_stocks = self.get_top_stocks(n=top_n)\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"TOP {top_n} Stock Picks\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "\n",
        "        pd.set_option('display.max_columns', None)\n",
        "        pd.set_option('display.width', None)\n",
        "        pd.set_option('display.max_colwidth', 30)\n",
        "\n",
        "        display_df = top_stocks[[\n",
        "            'Rank', 'Ticker', 'Company', 'Sector', 'Price',\n",
        "            'Momentum_Score', 'Quality_Score', 'Value_Score',\n",
        "            'LowVol_Score', 'Composite_Score'\n",
        "        ]].copy()\n",
        "\n",
        "        for col in ['Momentum_Score', 'Quality_Score', 'Value_Score', 'LowVol_Score', 'Composite_Score']:\n",
        "            display_df[col] = display_df[col].round(2)\n",
        "\n",
        "        print(display_df.to_string(index=False))\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"sector distribution\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "        sector_dist = top_stocks['Sector'].value_counts()\n",
        "        print(sector_dist)\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"factor score analysis\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "        factor_stats = top_stocks[[\n",
        "            'Momentum_Score', 'Quality_Score', 'Value_Score', 'LowVol_Score'\n",
        "        ]].describe()\n",
        "        print(factor_stats.round(2))\n",
        "\n",
        "        # Show high-momentum stocks\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"top 10 momentum stocks\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "        momentum_leaders = top_stocks.nlargest(10, 'Momentum_Score')[\n",
        "            ['Ticker', 'Company', 'Momentum_Score', 'Composite_Score']\n",
        "        ]\n",
        "        print(momentum_leaders.to_string(index=False))\n",
        "\n",
        "        return top_stocks\n",
        "\n",
        "    def analyze_specific_stocks(self, tickers_to_check):\n",
        "        \"\"\"\n",
        "        Check specific stocks if its on the list\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Analyzing sspecific stockpick\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "\n",
        "        if len(self.final_rankings) == 0:\n",
        "            print(\"No rankings available. Run screen_stocks() first.\")\n",
        "            return\n",
        "\n",
        "        for ticker in tickers_to_check:\n",
        "            if ticker in self.final_rankings['Ticker'].values:\n",
        "                stock_data = self.final_rankings[self.final_rankings['Ticker'] == ticker].iloc[0]\n",
        "\n",
        "                print(f\"\\n{ticker} - {stock_data['Company']}\")\n",
        "                print(f\"{'-'*60}\")\n",
        "                print(f\"Rank: #{int(stock_data['Rank'])} out of {len(self.final_rankings)}\")\n",
        "                print(f\"Composite Score: {stock_data['Composite_Score']:.2f}\")\n",
        "                print(f\"\\nFactor Breakdown:\")\n",
        "                print(f\"  Momentum:  {stock_data['Momentum_Score']:.2f} (Z-score: {stock_data['Momentum_Score_Z']:.2f})\")\n",
        "                print(f\"  Quality:   {stock_data['Quality_Score']:.2f} (Z-score: {stock_data['Quality_Score_Z']:.2f})\")\n",
        "                print(f\"  Value:     {stock_data['Value_Score']:.2f} (Z-score: {stock_data['Value_Score_Z']:.2f})\")\n",
        "                print(f\"  Low Vol:   {stock_data['LowVol_Score']:.2f} (Z-score: {stock_data['LowVol_Score_Z']:.2f})\")\n",
        "                print(f\"  Liquidity: {stock_data['Liquidity_Score']:.2f}\")\n",
        "            else:\n",
        "                print(f\"\\n{ticker}: Not found in rankings (may have been filtered out)\")\n",
        "\n",
        "    def export_results(self, filename='stock_picks.csv'):\n",
        "        \"\"\"\n",
        "        Export the final rankings to a CSV file.\n",
        "        \"\"\"\n",
        "        if not self.final_rankings.empty:\n",
        "            self.final_rankings.to_csv(filename, index=False)\n",
        "            print(f\"\\n Results successfully exported to {filename}\")\n",
        "        else:\n",
        "            print(\"\\n No rankings to export. Run screen_stocks() first.\")\n",
        "\n",
        "#main func to run\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"S&P 500 MULTI-FACTOR STOCK SCREENING ALGORITHM\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    screener = SNP500StockScreener()\n",
        "\n",
        "    # get tickers\n",
        "    tickers = screener.get_sp500_tickers()\n",
        "\n",
        "    # download stock data\n",
        "    success_count = screener.download_stock_data(\n",
        "        lookback_months=36,\n",
        "        batch_size=50,\n",
        "        delay=1\n",
        "    )\n",
        "\n",
        "    if success_count < 50:\n",
        "        print(\"\\n⚠ WARNING: Very few stocks downloaded.\")\n",
        "        response = input(\"\\nContinue with available data? (y/n): \")\n",
        "        if response.lower() != 'y':\n",
        "            exit()\n",
        "\n",
        "    # criteria\n",
        "    factor_weights = {\n",
        "        'momentum': 0.40,\n",
        "        'quality': 0.30,\n",
        "        'value': 0.20,\n",
        "        'low_vol': 0.10\n",
        "    }\n",
        "\n",
        "    rankings = screener.screen_stocks(factor_weights=factor_weights)\n",
        "\n",
        "    # get 50 picks\n",
        "    top_picks = screener.get_top_stocks()\n",
        "\n",
        "    # export\n",
        "    screener.export_results('sp500_stock_picks.csv')\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SCREENING COMPLETE!\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nTotal stocks ranked: {len(rankings)}\")\n",
        "    print(f\"Top picks selected: {len(top_picks)}\")\n",
        "    print(f\"Results saved\")"
      ]
    }
  ]
}